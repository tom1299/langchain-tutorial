from openai.types.chat import ChatCompletionAllowedToolChoiceParam, ChatCompletionAllowedToolsParam, ChatCompletionToolUnionParam, ChatCompletionFunctionToolParam
"""
Draft test cases for OpenAI tools with different tool choice configurations.

AI-Generated code (mostly)
"""

from openai import OpenAI, BadRequestError
import json

class TestOpenAITools:
    """
    From https://platform.openai.com/docs/guides/function-calling
    """

    def test_tools_with_typed_tool_choice(self):
        client = OpenAI()

        tool: ChatCompletionFunctionToolParam = {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get weather at a location",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {"type": "string"}
                    },
                    "required": ["location"]
                }
            }
        }

        allowed_tools: ChatCompletionAllowedToolsParam = {
            "mode": "auto",
            "tools":
            [
                {"type": "function", "function": {"name": "get_weather"}},
            ]
        }
        allowed_tool_choice: ChatCompletionAllowedToolChoiceParam = {
            "type": "allowed_tools",
            "allowed_tools": allowed_tools
        }

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "What's the weather in Boston?"}],
            tools=[tool],
            tool_choice=allowed_tool_choice
        )
        print(response)


    def test_openai_tools(self):
        """
        Exact example from the documentation using allowed_tools with tool_choice
        """
        client = OpenAI()

        # 1. Define a list of callable tools for the model
        tools = [
            {
                "type": "function",
                "name": "get_horoscope",
                "description": "Get today's horoscope for an astrological sign.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "sign": {
                            "type": "string",
                            "description": "An astrological sign like Taurus or Aquarius",
                        },
                    },
                    "required": ["sign"],
                },
            },
        ]


        def get_horoscope(sign):
            return f"{sign}: Next Tuesday you will befriend a baby otter."


        # Create a running input list we will add to over time
        input_list = [
            {"role": "user", "content": "What is my horoscope? I am an Aquarius."}
        ]

        # 2. Prompt the model with tools defined
        response = client.responses.create(
            model="gpt-4o-mini",
            tools=tools,
            input=input_list,
            tool_choice= {
                "type": "allowed_tools",
                "mode": "auto",
                "tools": [
                    {"type": "function", "name": "get_horoscope"}
                ]
            }
        )

        # Save function call outputs for subsequent requests
        input_list += response.output

        for item in response.output:
            if item.type == "function_call":
                if item.name == "get_horoscope":
                    # 3. Execute the function logic for get_horoscope
                    horoscope = get_horoscope(json.loads(item.arguments))

                    # 4. Provide function call results to the model
                    input_list.append({
                        "type": "function_call_output",
                        "call_id": item.call_id,
                        "output": json.dumps({
                            "horoscope": horoscope
                        })
                    })

        print("Final input:")
        print(input_list)

        response = client.responses.create(
            model="gpt-5",
            instructions="Respond only with a horoscope generated by a tool.",
            tools=tools,
            input=input_list,
        )

        # 5. The model should be able to give a response!
        print("Final output:")
        print(response.model_dump_json(indent=2))
        print("\n" + response.output_text)

    def test_openai_docs_example(self):
        from langchain.chat_models import init_chat_model
        from pydantic import BaseModel

        class ResponseSchema(BaseModel):
            response: str

        def get_weather(location: str) -> str:
            """Get weather at a location."""
            return f"It's always sunny in {location}!"

        model = init_chat_model("openai:gpt-4o-mini")

        structured_model = model.with_structured_output(
            ResponseSchema,
            tools=[get_weather],
            strict=True,
            include_raw=False,
        )

        response = structured_model.invoke("What's the weather in Boston?")
        print(response)

